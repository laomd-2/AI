{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from replacers import RegexReplacer\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove HTML tag pattern\n",
    "rc = re.compile(r\"\\<.*?\\>\")  \n",
    "# Replacer class\n",
    "replacer = RegexReplacer()\n",
    "# Lemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructTaggedDocuments(data):\n",
    "    return [TaggedDocument (utils.to_unicode(row).split(), ['Text' + '_%s' % str(index)])\n",
    "           for index, row in data.iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_text = pd.read_table(\"data/2/trainData.txt\", encoding='utf-8', header=None)[0]\n",
    "train_y = pd.read_table(\"data/2/trainLabel.txt\", header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    As long as there's been 3d technology, (1950's...\n",
       "1    William Shakespeare's Merchant of Venice portr...\n",
       "2    L'Auberge Espagnole is full of energy, and it'...\n",
       "3    As I was reading through the comments, I was s...\n",
       "4    The kind of B-movies from the 1950's that were...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitPhase(paragraph):\n",
    "    \"\"\" split paragraph to sentences \"\"\"\n",
    "    PunktTokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer()\n",
    "    return PunktTokenizer.tokenize(paragraph)\n",
    "\n",
    "def RemoveHTML(sentences):\n",
    "    \"\"\" remove HTML tags \"\"\"\n",
    "    return [rc.sub('',sentence) for sentence in sentences]\n",
    "\n",
    "def ReplaceAbbre(sentences):\n",
    "    \"\"\" Replace abbreviation \"\"\"\n",
    "    return [replacer.replace(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = train_text.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'William Shakespeare\\'s Merchant of Venice portrays 16th century Venice. Al Pacino plays Shylock, a Jewish loan shark who plots revenge on a Catholic that has looked down on him. The movie is a slow moving plot in the beginning that builds up throughout the two plus hours. The film gives a very good and believe appearance to it\\'s characters, especially Pacino. When hearing that Pacino plays a Jew one might think that it would not work looking at Pacino\\'s previous mobster type movie roles. Nonetheless it works very well, credit must be given to the costume designer\\'s and director\\'s of the film. The look of all the characters fits well with the time period the play takes place in. The costumes look like the Renaissance appearance one might envision to be.<br /><br />The film portrays a very anti-Semitic vibe. From the first minute to the last it is shown how the Catholic\\'s try to take advantage of the Jews in every way they can, even to the point of keeping them locked away in \"ghettos\" and not allowing them to regular jobs. In comparison to The Passion of the Christ, another recent film that people believed to be very Anti-Semitic, Merchant of Venice makes Passion look like a Jewish holiday. The film shows how the Jews, or at least Shylock wanted revenge for the mistreatment that the Jews received. The location shots also seem very timely and the scenery is at times very beautiful or very ugly depending on the scene of the film, making it just that much more realistic. Showing the beautiful and the ugly can also be seen as anti-Semitic because the ugly is usually shown around the Jews and the beautiful around the Catholics.<br /><br />Although the film clearly attempts to have a serious aura certain parts do add a bit of humor to the act. The oh so serious trial between Shylock and Antonio (Irons) adds a bit of humor when Portia (Collins) and Nerissa (Goldenhersh) come into the trial and decide who will be the victor and the defeated. That in itself might not be funny, but seeing it that they were women dressed up in disguise as men one might find it to be pretty amusing. The whole cross dressing scene, as compelling as it was could have probably been even more memorable had the make up artists and director Michael Radford taken notice that the two women still look like women and could easily be recognized. The director also could have seen into the fact that the women are speaking through their regular voices instead of trying to sound like men, which in part takes away from the scene but doesn\\'t kill it entirely.<br /><br />Overall the film gets a 7 out of 10 '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去掉HTML tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_html_text = all_text.apply(RemoveHTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"William Shakespeare's Merchant of Venice portrays 16th century Venice.\",\n",
       " 'Al Pacino plays Shylock, a Jewish loan shark who plots revenge on a Catholic that has looked down on him.',\n",
       " 'The movie is a slow moving plot in the beginning that builds up throughout the two plus hours.',\n",
       " \"The film gives a very good and believe appearance to it's characters, especially Pacino.\",\n",
       " \"When hearing that Pacino plays a Jew one might think that it would not work looking at Pacino's previous mobster type movie roles.\",\n",
       " \"Nonetheless it works very well, credit must be given to the costume designer's and director's of the film.\",\n",
       " 'The look of all the characters fits well with the time period the play takes place in.',\n",
       " 'The costumes look like the Renaissance appearance one might envision to be.The film portrays a very anti-Semitic vibe.',\n",
       " 'From the first minute to the last it is shown how the Catholic\\'s try to take advantage of the Jews in every way they can, even to the point of keeping them locked away in \"ghettos\" and not allowing them to regular jobs.',\n",
       " 'In comparison to The Passion of the Christ, another recent film that people believed to be very Anti-Semitic, Merchant of Venice makes Passion look like a Jewish holiday.',\n",
       " 'The film shows how the Jews, or at least Shylock wanted revenge for the mistreatment that the Jews received.',\n",
       " 'The location shots also seem very timely and the scenery is at times very beautiful or very ugly depending on the scene of the film, making it just that much more realistic.',\n",
       " 'Showing the beautiful and the ugly can also be seen as anti-Semitic because the ugly is usually shown around the Jews and the beautiful around the Catholics.Although the film clearly attempts to have a serious aura certain parts do add a bit of humor to the act.',\n",
       " 'The oh so serious trial between Shylock and Antonio (Irons) adds a bit of humor when Portia (Collins) and Nerissa (Goldenhersh) come into the trial and decide who will be the victor and the defeated.',\n",
       " 'That in itself might not be funny, but seeing it that they were women dressed up in disguise as men one might find it to be pretty amusing.',\n",
       " 'The whole cross dressing scene, as compelling as it was could have probably been even more memorable had the make up artists and director Michael Radford taken notice that the two women still look like women and could easily be recognized.',\n",
       " \"The director also could have seen into the fact that the women are speaking through their regular voices instead of trying to sound like men, which in part takes away from the scene but doesn't kill it entirely.Overall the film gets a 7 out of 10\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_html_text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 替换缩写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_abbr_text = no_html_text.apply(ReplaceAbbre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = constructTaggedDocuments(no_abbr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['william', \"shakespeare's\", 'merchant', 'venice', 'portrays', '16th', 'century', 'venice.', 'al', 'pacino', 'plays', 'shylock,', 'jewish', 'loan', 'shark', 'plots', 'revenge', 'catholic', 'looked', 'him.', 'movie', 'slow', 'moving', 'plot', 'beginning', 'builds', 'throughout', 'two', 'plus', 'hours.', 'film', 'gives', 'good', 'believe', 'appearance', 'characters,', 'especially', 'pacino.', 'hearing', 'pacino', 'plays', 'jew', 'one', 'might', 'think', 'would', 'work', 'looking', \"pacino's\", 'previous', 'mobster', 'type', 'movie', 'roles.', 'nonetheless', 'works', 'well,', 'credit', 'must', 'given', 'costume', \"designer's\", \"director's\", 'film.', 'look', 'characters', 'fits', 'well', 'time', 'period', 'play', 'takes', 'place', 'in.', 'costumes', 'look', 'like', 'renaissance', 'appearance', 'one', 'might', 'envision', 'be.<br', '/', '<br', '/', 'film', 'portrays', 'anti-semitic', 'vibe.', 'first', 'minute', 'last', 'shown', \"catholic's\", 'try', 'take', 'advantage', 'jews', 'every', 'way', 'can,', 'even', 'point', 'keeping', 'locked', 'away', 'ghettos', 'allowing', 'regular', 'jobs.', 'comparison', 'passion', 'christ,', 'another', 'recent', 'film', 'people', 'believed', 'anti-semitic,', 'merchant', 'venice', 'makes', 'passion', 'look', 'like', 'jewish', 'holiday.', 'film', 'shows', 'jews,', 'least', 'shylock', 'wanted', 'revenge', 'mistreatment', 'jews', 'received.', 'location', 'shots', 'also', 'seem', 'timely', 'scenery', 'times', 'beautiful', 'ugly', 'depending', 'scene', 'film,', 'making', 'much', 'realistic.', 'showing', 'beautiful', 'ugly', 'also', 'seen', 'anti-semitic', 'ugly', 'usually', 'shown', 'around', 'jews', 'beautiful', 'around', 'catholics.<br', '/', '<br', '/', 'although', 'film', 'clearly', 'attempts', 'serious', 'aura', 'certain', 'parts', 'add', 'bit', 'humor', 'act.', 'oh', 'serious', 'trial', 'shylock', 'antonio', 'irons', 'adds', 'bit', 'humor', 'portia', 'collins', 'nerissa', 'goldenhersh', 'come', 'trial', 'decide', 'victor', 'defeated.', 'might', 'funny,', 'seeing', 'women', 'dressed', 'disguise', 'men', 'one', 'might', 'find', 'pretty', 'amusing.', 'whole', 'cross', 'dressing', 'scene,', 'compelling', 'could', 'probably', 'even', 'memorable', 'make', 'artists', 'director', 'michael', 'radford', 'taken', 'notice', 'two', 'women', 'still', 'look', 'like', 'women', 'could', 'easily', 'recognized.', 'director', 'also', 'could', 'seen', 'fact', 'women', 'speaking', 'regular', 'voices', 'instead', 'trying', 'sound', 'like', 'men,', 'part', 'takes', 'away', 'scene', 'kill', 'entirely.<br', '/', '<br', '/', 'overall', 'film', 'gets', '7', '10'], tags=['Text_1'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据转vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from sklearn.linear_model import LogisticRegression     # 用逻辑回归做模型\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VecType = Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doc2Vec'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VecType.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    Parameters\n",
    "    def __init__(self, documents=None, corpus_file=None, dm_mean=None, dm=1, dbow_words=0, dm_concat=0,\n",
    "                 dm_tag_count=1, docvecs=None, docvecs_mapfile=None, comment=None, trim_rule=None, callbacks=(),\n",
    "                 **kwargs):\n",
    "    ----------\n",
    "    documents : iterable of list of :class:`~gensim.models.doc2vec.TaggedDocument`, optional\n",
    "        Input corpus, can be simply a list of elements, but for larger corpora,consider an iterable that streams\n",
    "        the documents directly from disk/network. If you don't supply `documents`, the model is\n",
    "        left uninitialized -- use if you plan to initialize it in some other way.\n",
    "    corpus_file : str, optional\n",
    "        Path to a corpus file in :class:`~gensim.models.word2vec.LineSentence` format.\n",
    "        You may use this argument instead of `sentences` to get performance boost. Only one of `sentences` or\n",
    "        `corpus_file` arguments need to be passed (or none of them).\n",
    "    dm : {1,0}, optional\n",
    "        Defines the training algorithm. If `dm=1`, 'distributed memory' (PV-DM) is used.\n",
    "        Otherwise, `distributed bag of words` (PV-DBOW) is employed.\n",
    "    vector_size : int, optional\n",
    "        Dimensionality of the feature vectors.\n",
    "    window : int, optional\n",
    "        The maximum distance between the current and predicted word within a sentence.\n",
    "    alpha : float, optional\n",
    "        The initial learning rate.\n",
    "    min_alpha : float, optional\n",
    "        Learning rate will linearly drop to `min_alpha` as training progresses.\n",
    "    seed : int, optional\n",
    "        Seed for the random number generator. Initial vectors for each word are seeded with a hash of\n",
    "        the concatenation of word + `str(seed)`. Note that for a fully deterministically-reproducible run,\n",
    "        you must also limit the model to a single worker thread (`workers=1`), to eliminate ordering jitter\n",
    "        from OS thread scheduling.\n",
    "        In Python 3, reproducibility between interpreter launches also requires use of the `PYTHONHASHSEED`\n",
    "        environment variable to control hash randomization.\n",
    "    min_count : int, optional\n",
    "        Ignores all words with total frequency lower than this.\n",
    "    max_vocab_size : int, optional\n",
    "        Limits the RAM during vocabulary building; if there are more unique\n",
    "        words than this, then prune the infrequent ones. Every 10 million word types need about 1GB of RAM.\n",
    "        Set to `None` for no limit.\n",
    "    sample : float, optional\n",
    "        The threshold for configuring which higher-frequency words are randomly downsampled,\n",
    "        useful range is (0, 1e-5).\n",
    "    workers : int, optional\n",
    "        Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "    epochs : int, optional\n",
    "        Number of iterations (epochs) over the corpus.\n",
    "    hs : {1,0}, optional\n",
    "        If 1, hierarchical softmax will be used for model training.\n",
    "        If set to 0, and `negative` is non-zero, negative sampling will be used.\n",
    "    negative : int, optional\n",
    "        If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\"\n",
    "        should be drawn (usually between 5-20).\n",
    "        If set to 0, no negative sampling is used.\n",
    "    ns_exponent : float, optional\n",
    "        The exponent used to shape the negative sampling distribution. A value of 1.0 samples exactly in proportion\n",
    "        to the frequencies, 0.0 samples all words equally, while a negative value samples low-frequency words more\n",
    "        than high-frequency words. The popular default value of 0.75 was chosen by the original Word2Vec paper.\n",
    "        More recently, in https://arxiv.org/abs/1804.04212, Caselles-Dupré, Lesaint, & Royo-Letelier suggest that\n",
    "        other values may perform better for recommendation applications.\n",
    "    dm_mean : {1,0}, optional\n",
    "        If 0 , use the sum of the context word vectors. If 1, use the mean.\n",
    "        Only applies when `dm` is used in non-concatenative mode.\n",
    "    dm_concat : {1,0}, optional\n",
    "        If 1, use concatenation of context vectors rather than sum/average;\n",
    "        Note concatenation results in a much-larger model, as the input\n",
    "        is no longer the size of one (sampled or arithmetically combined) word vector, but the\n",
    "        size of the tag(s) and all words in the context strung together.\n",
    "    dm_tag_count : int, optional\n",
    "        Expected constant number of document tags per document, when using\n",
    "        dm_concat mode.\n",
    "    dbow_words : {1,0}, optional\n",
    "        If set to 1 trains word-vectors (in skip-gram fashion) simultaneous with DBOW\n",
    "        doc-vector training; If 0, only trains doc-vectors (faster).\n",
    "    trim_rule : function, optional\n",
    "        Vocabulary trimming rule, specifies whether certain words should remain in the vocabulary,\n",
    "        be trimmed away, or handled using the default (discard if word count < min_count).\n",
    "        Can be None (min_count will be used, look to :func:`~gensim.utils.keep_vocab_item`),\n",
    "        or a callable that accepts parameters (word, count, min_count) and returns either\n",
    "        :attr:`gensim.utils.RULE_DISCARD`, :attr:`gensim.utils.RULE_KEEP` or :attr:`gensim.utils.RULE_DEFAULT`.\n",
    "        The rule, if given, is only used to prune vocabulary during current method call and is not stored as part\n",
    "        of the model.\n",
    "\n",
    "        The input parameters are of the following types:\n",
    "            * `word` (str) - the word we are examining\n",
    "            * `count` (int) - the word's frequency count in the corpus\n",
    "            * `min_count` (int) - the minimum count threshold.\n",
    "\n",
    "    callbacks : :obj: `list` of :obj: `~gensim.models.callbacks.CallbackAny2Vec`, optional\n",
    "        List of callbacks that need to be executed/run at specific stages during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3c4d00d6c0ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                      epochs=25, alpha=0.05, seed=4)\n\u001b[0;32m      6\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtext_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m             **kwargs)\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[0;32m    554\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[1;32mc:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# blocks if workers too slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# a thread reporting that it finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filename='trained_vecs/2/trainData_clean.vec'\n",
    "text_model = Doc2Vec(min_count=1, window=5, \n",
    "                     vector_size=150, \n",
    "                     negative=25, workers=4, \n",
    "                     epochs=25, alpha=0.05, seed=4)\n",
    "text_model.build_vocab(sentences)\n",
    "text_model.train(sentences, total_examples=text_model.corpus_count, epochs=text_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model.save(filename)\n",
    "# text_model = Doc2Vec.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([text_model.docvecs['Text_'+str(i)] for i in range(len(train_text))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.97976339e-01, -7.52540231e-01,  2.04513431e+00,\n",
       "        -8.55905533e-01, -2.29428172e+00, -1.99305296e+00,\n",
       "        -1.53948152e+00,  4.97840822e-01, -7.53712535e-01,\n",
       "         1.28665245e+00, -8.77376676e-01,  7.33760953e-01,\n",
       "        -1.17904317e+00,  4.22223330e-01,  8.00953448e-01,\n",
       "        -2.71314240e+00, -2.69650400e-01,  1.90351105e+00,\n",
       "        -1.12113571e+00, -5.28665245e-01, -4.82490778e-01,\n",
       "        -2.89393616e+00, -3.64178754e-02,  1.03160334e+00,\n",
       "         1.20031405e-02, -1.09143043e+00, -4.24810499e-01,\n",
       "         1.24755955e+00,  1.40458322e+00,  7.50815094e-01,\n",
       "         6.11275546e-02, -7.51111209e-01, -7.95800745e-01,\n",
       "         1.43203139e+00,  5.22482991e-01, -4.60974169e+00,\n",
       "        -1.20615780e+00, -1.52807903e+00, -1.48960841e+00,\n",
       "         1.95232081e+00, -2.35811925e+00,  2.04465318e+00,\n",
       "        -8.03631186e-01, -7.55493879e-01,  5.69580138e-01,\n",
       "         1.00461555e+00,  3.68598342e-01,  1.31550372e+00,\n",
       "        -1.13665140e+00,  8.97321045e-01,  4.59804088e-01,\n",
       "        -3.34411353e-01, -6.77219391e-01,  2.91227520e-01,\n",
       "         8.97407234e-02,  1.75278258e+00,  2.34907180e-01,\n",
       "         4.14764792e-01, -7.12394595e-01,  1.38676673e-01,\n",
       "        -9.40371156e-01,  1.52946079e+00, -1.48777688e+00,\n",
       "         1.63192964e+00,  1.26820612e+00, -2.12903637e-02,\n",
       "        -1.36910868e+00, -9.95874465e-01, -1.96960449e+00,\n",
       "         3.09413046e-01, -1.84378609e-01,  8.12829137e-01,\n",
       "        -4.64250326e-01, -3.08079779e-01, -8.36512804e-01,\n",
       "         3.01531523e-01, -9.40912515e-02,  3.54036272e-01,\n",
       "         1.47551680e+00, -5.60803473e-01,  1.43103302e+00,\n",
       "        -1.21486855e+00, -8.97499502e-01,  6.55645370e-01,\n",
       "         3.28649473e+00,  9.63200152e-01, -1.16784930e+00,\n",
       "        -1.47408509e+00, -1.10693836e+00,  2.95716000e+00,\n",
       "        -6.97986901e-01, -4.52277586e-02, -2.78301835e+00,\n",
       "        -5.66791534e-01, -1.08601224e+00,  4.78509218e-01,\n",
       "         4.80519682e-01,  3.69951606e-01, -3.56735677e-01,\n",
       "        -3.76085758e-01,  1.46727729e+00, -2.47732258e+00,\n",
       "        -3.05293679e-01,  2.19801497e+00, -1.85361244e-02,\n",
       "        -3.50447559e+00,  3.80511498e+00, -3.21740240e-01,\n",
       "         7.67795920e-01,  1.03196251e+00, -1.29891837e+00,\n",
       "        -1.40024006e-01, -8.28948379e-01,  8.11098695e-01,\n",
       "        -1.32821965e+00,  1.17829204e+00,  7.41103411e-01,\n",
       "        -5.43604851e-01,  1.25428677e+00,  3.32598269e-01,\n",
       "        -1.93457097e-01,  1.46588182e+00, -2.57390022e-01,\n",
       "         2.95089960e+00, -4.58640605e-01,  9.78732258e-02,\n",
       "         1.86768925e+00,  2.14295417e-01,  8.77685905e-01,\n",
       "         7.49411881e-01, -3.04880476e+00,  2.11728311e+00,\n",
       "        -9.83256459e-01, -1.69161654e+00, -1.28906465e+00,\n",
       "        -8.01262736e-01, -8.41364145e-01, -2.09349990e-02,\n",
       "         2.91886121e-01, -3.30327177e+00,  5.51175058e-01,\n",
       "         2.57838011e+00,  4.41574842e-01, -1.30946004e+00,\n",
       "        -1.87821496e+00,  2.51660943e+00,  1.02694321e+00,\n",
       "        -3.53094667e-01, -2.89149594e+00, -1.20707321e+00],\n",
       "       [ 2.66470760e-01,  8.25533330e-01, -1.11483502e+00,\n",
       "        -2.49597669e-01, -1.32754669e-01,  1.21572983e+00,\n",
       "         3.15755892e+00, -2.45039940e+00,  4.01373672e+00,\n",
       "         3.78742027e+00, -8.22728634e-01, -8.06471884e-01,\n",
       "        -1.14468014e+00,  5.38242221e-01, -2.62405872e+00,\n",
       "        -1.08627307e+00,  1.91338921e+00, -1.30319214e+00,\n",
       "         8.85124922e-01,  3.20290828e+00, -1.81250751e+00,\n",
       "         2.34375834e+00, -5.83458960e-01,  1.00569040e-01,\n",
       "        -1.12016761e+00,  1.40802777e+00,  1.00631046e+00,\n",
       "         1.03751230e+00, -3.24515295e+00, -1.00106537e+00,\n",
       "         3.00082660e+00, -2.25743604e+00, -1.68938264e-02,\n",
       "        -1.65129066e+00,  1.82825339e+00, -1.96654618e+00,\n",
       "         1.53698146e+00, -2.66943550e+00, -2.90468621e+00,\n",
       "         5.36410630e-01,  1.19287276e+00,  1.60935402e-01,\n",
       "         2.11596668e-01, -2.60342789e+00,  2.98858070e+00,\n",
       "        -1.58944201e+00,  9.42824125e-01, -9.45360899e-01,\n",
       "         5.17073631e-01, -6.09583080e-01,  4.73653302e-02,\n",
       "         2.86538148e+00,  1.14489961e+00, -1.53560966e-01,\n",
       "        -8.64140511e-01,  3.64670485e-01,  6.85288668e-01,\n",
       "         3.35641551e+00, -7.97793627e-01, -2.01516652e+00,\n",
       "         2.75361156e+00,  1.65897107e+00,  7.45497108e-01,\n",
       "        -8.49027753e-01, -4.15571213e+00, -3.00017166e+00,\n",
       "        -1.43665183e+00,  1.09085083e-01, -4.38375846e-02,\n",
       "        -2.35986665e-01,  4.81013834e-01,  1.23662269e+00,\n",
       "         8.76260549e-02, -9.62390065e-01, -2.03620124e+00,\n",
       "        -3.06513868e-02,  6.63683563e-02,  9.33842957e-01,\n",
       "         2.11139393e+00, -1.66791260e+00,  8.45269978e-01,\n",
       "         1.41211259e+00, -9.67257380e-01,  1.14728081e+00,\n",
       "         9.82151747e-01,  1.02648407e-03,  5.09567916e-01,\n",
       "         2.43676066e+00,  1.14735234e+00,  1.79068756e+00,\n",
       "         9.86886322e-01,  1.75538456e+00,  1.07986189e-01,\n",
       "        -2.82838392e+00,  5.10506928e-01,  7.28289306e-01,\n",
       "         1.75859630e+00,  1.63860655e+00, -1.09508479e+00,\n",
       "        -7.20066965e-01,  1.36571085e+00,  1.82939732e+00,\n",
       "        -6.02499366e-01, -1.75729775e+00,  2.08785042e-01,\n",
       "        -2.27093863e+00,  6.44640565e-01, -1.29066431e-03,\n",
       "        -1.07817447e+00,  3.08157849e+00,  1.80861080e+00,\n",
       "        -1.48733664e+00, -1.98081923e+00,  5.30812025e+00,\n",
       "         4.23089452e-02, -7.85392046e-01, -8.31939220e-01,\n",
       "         3.25701022e+00, -7.76119351e-01, -1.20118928e+00,\n",
       "        -9.12511230e-01, -1.02475810e+00, -5.68525672e-01,\n",
       "         9.50304389e-01,  9.58862126e-01,  7.11989284e-01,\n",
       "         1.39936626e+00, -2.87431979e+00,  2.12703466e+00,\n",
       "         2.51008320e+00, -1.39592397e+00, -3.52548623e+00,\n",
       "         2.76334000e+00, -9.59204495e-01, -1.19898939e+00,\n",
       "        -3.43101788e+00, -3.81700158e+00, -1.22262537e-01,\n",
       "         1.77351308e+00, -1.87498546e+00,  9.14761066e-01,\n",
       "        -6.87022805e-01,  7.07482159e-01,  2.18733644e+00,\n",
       "         9.67334434e-02,  1.08472705e+00,  5.74347258e-01,\n",
       "         2.56544423e+00, -6.57065749e-01,  1.46000952e-01],\n",
       "       [ 1.41920269e+00, -5.05307555e-01, -7.01754391e-01,\n",
       "         2.08099937e+00,  1.48241045e-02, -2.59269744e-01,\n",
       "         7.93504238e-01,  5.13399899e-01, -8.42095733e-01,\n",
       "        -1.32458901e+00, -1.93068415e-01,  2.49327922e+00,\n",
       "        -7.32400775e-01,  7.67066240e-01,  6.89986646e-01,\n",
       "        -8.57131004e-01,  5.33843756e-01,  1.25042820e+00,\n",
       "        -6.85415745e-01,  4.97270823e-01, -1.66973674e+00,\n",
       "        -1.90729976e+00,  6.75378144e-01, -2.61999440e+00,\n",
       "         5.05807042e-01,  8.22073072e-02,  1.85694742e+00,\n",
       "        -1.09748900e+00,  2.12130857e+00,  1.55856335e+00,\n",
       "         1.22355950e+00, -1.88326985e-01,  2.94241250e-01,\n",
       "         1.23384334e-02,  1.24541223e+00,  9.33977902e-01,\n",
       "        -2.38992834e+00,  9.78362143e-01,  7.00717211e-01,\n",
       "         3.38093138e+00, -4.18499708e-01,  7.94840276e-01,\n",
       "         1.60938239e+00, -9.65446174e-01,  2.49950933e+00,\n",
       "        -2.20148742e-01, -1.08832407e+00,  6.06115043e-01,\n",
       "        -2.28885031e+00,  1.34545016e+00,  8.92206252e-01,\n",
       "         1.03188552e-01,  3.03724885e-01,  8.87876749e-01,\n",
       "         4.65809971e-01, -2.27932835e+00,  1.15346265e+00,\n",
       "         2.35916924e+00, -3.25843978e+00, -1.15344596e+00,\n",
       "         2.25255156e+00, -9.75390017e-01, -1.44615442e-01,\n",
       "         1.53607264e-01,  3.48478824e-01,  1.13990247e+00,\n",
       "         2.61306763e-01, -2.06672764e+00,  7.69247890e-01,\n",
       "         6.69001043e-01, -5.14143050e-01, -6.88572586e-01,\n",
       "         7.91341588e-02, -2.36464882e+00, -1.27927864e+00,\n",
       "         1.49042082e+00,  1.01843476e-01, -1.70060408e+00,\n",
       "         2.36147299e-01, -1.50297415e+00,  1.32427466e+00,\n",
       "        -6.81195080e-01,  2.02980042e-01, -8.74285340e-01,\n",
       "         8.88233110e-02,  9.22261298e-01,  4.34686691e-01,\n",
       "        -5.03732681e-01, -1.40613341e+00,  1.25313461e+00,\n",
       "        -1.65493011e+00, -8.39227676e-01,  1.02006733e-01,\n",
       "        -1.29252040e+00,  1.07075274e+00, -1.73985219e+00,\n",
       "         1.16167581e+00, -9.54655409e-01, -1.26127279e+00,\n",
       "        -8.49294782e-01, -1.41292036e+00,  6.37799740e-01,\n",
       "         9.22700346e-01, -1.09522808e+00, -1.03758883e+00,\n",
       "        -1.66886961e+00,  6.59475088e-01, -1.22713926e-03,\n",
       "         2.44133472e-01,  1.51176822e+00,  2.33774021e-01,\n",
       "         7.90096879e-01, -6.95076585e-01,  1.90018415e-01,\n",
       "        -1.42936778e+00,  3.56777370e-01, -1.04582000e+00,\n",
       "         1.47133052e+00, -4.73987579e-01, -1.32830524e+00,\n",
       "        -1.98110628e+00,  3.74561459e-01,  5.03216147e-01,\n",
       "         5.30067801e-01, -3.97473842e-01, -2.21954077e-01,\n",
       "        -7.90034115e-01, -1.41593492e+00, -2.25705123e+00,\n",
       "        -1.24831295e+00,  1.19054294e+00, -3.66459221e-01,\n",
       "         9.28149819e-01,  3.56734782e-01,  2.22954825e-01,\n",
       "        -2.58975551e-02, -8.23027194e-01,  1.69769847e+00,\n",
       "        -1.80502221e-01, -6.25910044e-01,  2.83303833e+00,\n",
       "        -1.38822329e+00, -2.10101700e+00,  9.04933751e-01,\n",
       "         7.58498430e-01, -1.67124534e+00,  7.16303766e-01,\n",
       "         4.71522272e-01, -5.37146553e-02,  1.87652171e+00],\n",
       "       [ 1.13138568e+00,  1.39629769e+00,  1.50107789e+00,\n",
       "        -6.21015668e-01, -3.32760215e-01, -5.57703115e-02,\n",
       "         7.03716338e-01,  1.86078429e-01,  1.88748682e+00,\n",
       "        -1.84804177e+00,  1.57841516e+00,  2.78701633e-01,\n",
       "        -1.56256187e+00,  2.07009459e+00, -6.92528903e-01,\n",
       "        -2.02546334e+00,  6.60720021e-02,  7.14707017e-01,\n",
       "        -3.09704113e+00,  1.69544721e+00, -3.02364469e-01,\n",
       "        -1.43535829e+00, -6.09000742e-01, -3.21929961e-01,\n",
       "        -2.88864398e+00,  5.41526750e-02,  3.40812132e-02,\n",
       "         1.66627026e+00,  2.16212586e-01,  1.59671962e+00,\n",
       "         2.72922754e+00, -1.14387032e-02, -3.33235443e-01,\n",
       "         2.25799417e+00,  2.30595541e+00, -1.18610449e-02,\n",
       "        -2.08976817e+00, -8.56114745e-01, -1.51960576e+00,\n",
       "         1.51825500e+00, -2.97599912e-01,  1.01188850e+00,\n",
       "         2.90352893e+00,  1.72126031e+00,  1.80811214e+00,\n",
       "        -1.39951003e+00,  5.93791544e-01,  2.91862130e+00,\n",
       "        -2.20974469e+00, -1.53442717e+00, -3.29775482e-01,\n",
       "         1.24394584e+00, -9.92278576e-01, -1.42053887e-01,\n",
       "        -2.75229383e+00, -2.13907385e+00,  4.06861790e-02,\n",
       "        -1.61457539e+00, -2.52573228e+00,  1.37555766e+00,\n",
       "        -4.60222103e-02, -3.15882057e-01, -9.49697971e-01,\n",
       "         1.39793527e+00, -1.16963148e+00,  2.66302419e+00,\n",
       "         2.49902797e+00, -3.39706659e+00,  1.88490438e+00,\n",
       "         8.17450941e-01, -1.98371696e+00, -2.36740366e-01,\n",
       "         2.39856505e+00,  2.60320210e+00, -1.04869895e-01,\n",
       "         9.90681469e-01,  2.77799797e+00, -5.56633234e-01,\n",
       "         1.86263537e+00, -1.62172413e+00, -1.60080135e+00,\n",
       "         9.77135658e-01, -3.00600529e-01, -6.00749671e-01,\n",
       "        -8.12546790e-01,  1.39396453e+00,  1.81733358e+00,\n",
       "        -6.69969797e-01,  1.47162485e+00,  8.66935134e-01,\n",
       "         5.68608701e-01,  1.09033704e+00, -4.58773732e-01,\n",
       "        -3.84377867e-01,  5.51906765e-01,  5.15686870e-02,\n",
       "         6.62721336e-01,  7.71507502e-01,  4.34409231e-01,\n",
       "         1.39420629e+00,  1.66234970e+00,  6.88578963e-01,\n",
       "         8.29767764e-01, -4.26876098e-01, -4.58541751e-01,\n",
       "        -9.16797161e-01, -1.35648966e+00, -1.14781201e+00,\n",
       "        -7.59616137e-01, -8.77142847e-01,  8.40949118e-01,\n",
       "         4.58353758e-01, -4.24577773e-01,  1.07585418e+00,\n",
       "         6.37053847e-01,  3.25946286e-02, -1.85378599e+00,\n",
       "         2.30102515e+00,  1.07776020e-02, -1.62352696e-01,\n",
       "        -2.31176424e+00, -1.84410965e+00, -1.89913535e+00,\n",
       "         2.11453724e+00, -3.71522307e-01,  3.40996869e-02,\n",
       "         2.73487389e-01, -2.62048542e-01,  1.52296275e-01,\n",
       "        -1.23298669e+00,  5.15178740e-01, -2.09775895e-01,\n",
       "         1.41704214e+00, -1.88866541e-01, -2.01931572e+00,\n",
       "        -3.73640680e+00,  1.10064864e+00,  1.22299182e+00,\n",
       "        -2.67048335e+00, -4.09988433e-01, -5.39320648e-01,\n",
       "         1.90357044e-01, -1.25335500e-01, -1.75005817e+00,\n",
       "        -4.02147919e-01,  1.28976059e+00,  1.59492016e+00,\n",
       "        -2.59812951e-01, -2.38965720e-01,  3.15357059e-01],\n",
       "       [ 1.29555905e+00, -1.77266109e+00,  1.77489996e+00,\n",
       "         7.42938221e-01, -9.49006081e-01, -2.62735081e+00,\n",
       "        -9.98406485e-02, -2.39803910e+00, -2.40094376e+00,\n",
       "        -8.57170284e-01,  4.91972953e-01, -2.17292190e+00,\n",
       "         2.39861712e-01,  1.76643991e+00,  3.00669217e+00,\n",
       "        -1.44385338e+00,  1.74910259e+00, -9.45052877e-02,\n",
       "        -8.95534575e-01, -1.40435600e+00,  3.98515016e-01,\n",
       "        -1.15112388e+00,  5.28157771e-01, -1.02417953e-01,\n",
       "         3.83938909e+00, -2.67312026e+00,  7.44331777e-01,\n",
       "         1.41212201e+00, -6.29087806e-01, -1.45803821e+00,\n",
       "        -8.30840707e-01, -2.33306617e-01, -3.90524507e-01,\n",
       "         8.09080720e-01,  1.35749722e+00,  6.33279026e-01,\n",
       "        -7.94769943e-01, -1.95585608e+00, -2.04764271e+00,\n",
       "         1.09306788e+00, -4.16534126e-01, -1.14045215e+00,\n",
       "         2.45148087e+00, -2.05468321e+00, -1.08935809e+00,\n",
       "         2.29977772e-01, -1.45744801e+00,  1.08707666e+00,\n",
       "        -2.53063035e+00, -2.38168925e-01, -8.77019018e-02,\n",
       "         4.17736411e-01,  1.10644805e+00, -8.16368222e-01,\n",
       "        -1.56019652e+00, -2.69947624e+00,  1.46560550e+00,\n",
       "        -2.00098574e-01,  1.40824705e-01, -1.74393547e+00,\n",
       "         1.47778440e+00,  1.71425417e-01, -2.62821078e+00,\n",
       "         7.06184626e-01, -1.80050635e+00, -1.10427046e+00,\n",
       "        -8.14888299e-01,  2.21202397e+00, -3.28141481e-01,\n",
       "         7.93997571e-02,  1.20525587e+00, -1.19698644e-02,\n",
       "        -4.28006840e+00,  7.94345617e-01, -5.11699021e-01,\n",
       "         2.89734364e-01,  5.54908693e-01,  1.76812780e+00,\n",
       "         4.55006361e-01, -4.24917310e-01,  1.34973731e-02,\n",
       "         9.36821222e-01, -1.81063688e+00,  5.28387249e-01,\n",
       "         2.18627620e+00, -7.24911332e-01,  1.55662346e+00,\n",
       "         1.02541590e+00,  2.61805832e-01,  2.82845616e-01,\n",
       "        -1.38146973e+00, -3.81182837e+00,  1.81330407e+00,\n",
       "        -7.63277888e-01, -7.76476860e-01,  6.47956729e-01,\n",
       "         2.95461953e-01,  7.53373861e-01, -2.03092623e+00,\n",
       "         6.94908679e-01,  1.88316047e+00,  8.77172709e-01,\n",
       "         1.49238169e+00,  5.90321302e-01, -3.28287530e+00,\n",
       "        -4.72068340e-01,  1.94490886e+00, -1.08867690e-01,\n",
       "         1.82332444e+00,  3.82975602e+00,  9.74831060e-02,\n",
       "        -1.28502965e+00,  5.96363127e-01,  3.03007746e+00,\n",
       "         4.64677781e-01, -2.20765376e+00,  4.34543228e+00,\n",
       "        -8.23811769e-01,  1.12047899e+00, -1.23081541e+00,\n",
       "        -8.60974371e-01, -1.66143194e-01, -7.73184061e-01,\n",
       "        -2.70686841e+00, -1.37270570e-01, -2.49488139e+00,\n",
       "         2.75910020e-01,  4.33771372e-01, -1.76465130e+00,\n",
       "        -9.64599907e-01,  2.07511276e-01,  1.10063636e+00,\n",
       "        -7.26648569e-01, -3.05350542e+00, -2.67948270e-01,\n",
       "         1.50422537e+00, -1.55674946e+00, -5.17330803e-02,\n",
       "        -2.24131680e+00, -7.81187236e-01,  2.17276478e+00,\n",
       "         3.72828424e-01, -5.71505725e-02, -2.04992995e-01,\n",
       "        -5.36338854e+00,  1.90292263e+00, -1.69857904e-01,\n",
       "         3.48554909e-01, -2.96564484e+00,  1.00688064e+00]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\laomd\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8710001887659224"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "cross_val_score(model, data, train_y, cv=5, scoring='accuracy').mean()   # window=5, dm=1(distributed memory), min_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from logistic_model import logistic_regression, base\n",
    "reload(base)\n",
    "reload(logistic_regression)\n",
    "from logistic_model.logistic_regression import SimpleLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SimpleLogisticRegression()\n",
    "clf.fit(data, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8714583333333333"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SimpleLogisticRegression(), data, train_y, cv=5, scoring='accuracy').mean()   # window=5, dm=1(distributed memory), min_count=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
